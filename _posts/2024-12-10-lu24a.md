---
title: Improving Multi-candidate Speculative Decoding
section: Inference
abstract: Speculative Decoding (SD) is a technique to accelerate the inference of
  Large Language Models (LLMs) by using a lower complexity draft model to propose
  candidate tokens verified by a larger target model. To further improve efficiency,
  Multi-Candidate Speculative Decoding (MCSD) improves upon this by sampling multiple
  candidate tokens from the draft model at each step and verifying them in parallel,
  thus increasing the chances of accepting a token and reducing generation time. Existing
  MCSD methods rely on the draft model to initialize the multi-candidate sequences
  and use static length and tree attention structure for draft generation. However,
  such an approach suffers from the draft and target modelâ€™s output distribution differences,
  especially in a dynamic generation context. In this work, we introduce a new version
  of MCSD that includes a target model initialized multi-candidate generation, a dynamic
  sliced topology-aware causal mask for dynamic length adjustment, and decision models
  to optimize early stopping. We experimented with our method on Llama 2-7B and its
  variants and observed a maximum 27.5% speedup compared to our MCSD baseline across
  three benchmarks with Llama 2-7B as the target model and JackFram 68M as the draft
  model. Additionally, we evaluate the effects of using the target model initialized
  multi-candidate process with different draft models on output quality.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lu24a
month: 0
tex_title: Improving Multi-candidate Speculative Decoding
firstpage: 382
lastpage: 394
page: 382-394
order: 382
cycles: false
bibtex_author: Lu, XiaoFan and Zeng, Yixiao and Levorato, Marco and Ma, FeiYang and
  Yu, ZiXu
author:
- given: XiaoFan
  family: Lu
- given: Yixiao
  family: Zeng
- given: Marco
  family: Levorato
- given: FeiYang
  family: Ma
- given: ZiXu
  family: Yu
date: 2024-12-10
address:
container-title: Proceedings of The 4th NeurIPS Efficient Natural Language and Speech
  Processing Workshop
volume: '262'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 12
  - 10
pdf: https://raw.githubusercontent.com/mlresearch/v262/main/assets/lu24a/lu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
