---
title: On the Efficiency of NLP-Inspired Methods for Tabular Deep Learning
section: Benchmark \& Evaluation
abstract: Recent advancements in tabular deep learning (DL) have led to substantial
  performance improvements, surpassing the capabilities of traditional models. With
  the adoption of techniques from natural language processing (NLP), such as language
  model-based approaches, DL models for tabular data have also grown in complexity
  and size. Although tabular datasets do not typically pose scalability issues, the
  escalating size of these models has raised efficiency concerns. Despite its importance,
  efficiency has been relatively underexplored in tabular DL research. This paper
  critically examines the latest innovations in tabular DL, with a dual focus on performance
  and computational efficiency. The source code is available at https://github.com/basf/mamba-tabular.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: f-thielmann24a
month: 0
tex_title: On the Efficiency of {NLP}-Inspired Methods for Tabular Deep Learning
firstpage: 532
lastpage: 539
page: 532-539
order: 532
cycles: false
bibtex_author: F Thielmann, Anton and Samiee, Soheila
author:
- given: Anton
  family: F Thielmann
- given: Soheila
  family: Samiee
date: 2024-12-10
address:
container-title: Proceedings of The 4th NeurIPS Efficient Natural Language and Speech
  Processing Workshop
volume: '262'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 12
  - 10
pdf: https://raw.githubusercontent.com/mlresearch/v262/main/assets/f-thielmann24a/f-thielmann24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
