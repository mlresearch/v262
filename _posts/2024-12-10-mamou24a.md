---
title: Dynamic Speculation Lookahead Accelerates Speculative Decoding of Large Language
  Models
section: Inference
abstract: Speculative decoding is commonly used for reducing the inference latency
  of large language models. Its effectiveness depends highly on the speculation lookahead
  (SL)-the number of tokens generated by the draft model at each iteration. In this
  work we show that the common practice of using the same SL for all iterations (static
  SL) is suboptimal. We introduce DISCO (DynamIc SpeCulation lookahead Optimization),
  a novel method for dynamically selecting the SL. Our experiments with four datasets
  show that DISCO reaches an average speedup of 10% compared to the best static SL
  baseline, while generating the exact same text.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mamou24a
month: 0
tex_title: Dynamic Speculation Lookahead Accelerates Speculative Decoding of Large
  Language Models
firstpage: 456
lastpage: 467
page: 456-467
order: 456
cycles: false
bibtex_author: Mamou, Jonathan and Pereg, Oren and Korat, Daniel and Berchansky, Moshe
  and Timor, Nadav and Wasserblat, Moshe and Schwartz, Roy
author:
- given: Jonathan
  family: Mamou
- given: Oren
  family: Pereg
- given: Daniel
  family: Korat
- given: Moshe
  family: Berchansky
- given: Nadav
  family: Timor
- given: Moshe
  family: Wasserblat
- given: Roy
  family: Schwartz
date: 2024-12-10
address:
container-title: Proceedings of The 4th NeurIPS Efficient Natural Language and Speech
  Processing Workshop
volume: '262'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 12
  - 10
pdf: https://raw.githubusercontent.com/mlresearch/v262/main/assets/mamou24a/mamou24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
