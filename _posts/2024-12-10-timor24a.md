---
title: Distributed Speculative Inference of Large Language Models is Provably Faster
section: Inference
abstract: 'Accelerating the inference of large language models (LLMs) is an important
  challenge in artificial intelligence. This paper introduces Distributed Speculative
  Inference (DSI), a novel distributed inference algorithm that is provably faster
  than speculative inference (SI) [leviathan2023fast, chen2023accelerating, miao2023specinfer]
  and traditional autoregressive inference (non-SI). Like other SI algorithms, DSI
  works on frozen LLMs, requiring no training or architectural modifications, and
  it preserves the target distribution. Prior studies on SI have demonstrated empirical
  speedups (compared to non-SI) but require fast and accurate drafters, which are
  often unavailable in practice. We identify a gap where SI can be slower than non-SI
  given slower or less accurate drafters. We close this gap by proving that DSI is
  faster than both SI and non-SIâ€”given any drafters. DSI introduces a novel type of
  task parallelism called Speculation Parallelism (SP), which orchestrates target
  and drafter instances to overlap in time, creating a new foundational tradeoff between
  computational resources and latency. DSI is not only faster than SI but also supports
  LLMs that cannot be accelerated with SI. Our simulations show speedups of off-the-shelf
  LLMs in realistic single-node settings where DSI is 1.29-1.92x faster than SI. Our
  code is open-sourced: github.com/keyboardAnt/distributed-speculative-inference'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: timor24a
month: 0
tex_title: Distributed Speculative Inference of Large Language Models is Provably
  Faster
firstpage: 336
lastpage: 354
page: 336-354
order: 336
cycles: false
bibtex_author: Timor, Nadav and Mamou, Jonathan and Pereg, Oren and Berchansky, Moshe
  and Korat, Daniel and Wasserblat, Moshe and Galanti, Tomer and Gordon, Michal and
  Harel, David
author:
- given: Nadav
  family: Timor
- given: Jonathan
  family: Mamou
- given: Oren
  family: Pereg
- given: Moshe
  family: Berchansky
- given: Daniel
  family: Korat
- given: Moshe
  family: Wasserblat
- given: Tomer
  family: Galanti
- given: Michal
  family: Gordon
- given: David
  family: Harel
date: 2024-12-10
address:
container-title: Proceedings of The 4th NeurIPS Efficient Natural Language and Speech
  Processing Workshop
volume: '262'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 12
  - 10
pdf: https://raw.githubusercontent.com/mlresearch/v262/main/assets/timor24a/timor24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
